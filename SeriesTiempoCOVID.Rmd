--- 
title: "Análisis de Series de Tiempo relacionados con COVID19"
author: "GRUPO 6: Maria José Reina Torres, Sonia Yurany Gallego Paz, Juan José León Tabares"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
output_dir: "docs"
documentclass: book
biblio-style: apalike
link-citations: yes
github-repo: Familia GSM\Documents\Data Science\Series de tiempo
description: "Se incluye un análisis de series de tiempo con datos relacionados con el COVID 19 desde 2020 hasta enero de 2024"
---

# Introducción:

 La base de datos owid-covid-data es una colección de datos de COVID-19 mantenidos por Our World in Data. Los datos que encuentra aquí son los casos confirmados y muertes, estos datos se recopilan del Panel de control de coronavirus de la Organización Mundial de la Salud, el conjunto de datos de casos y muertes se actualiza diariamente.
 
Nota 1: Las marcas de hora y fecha reflejan cuándo la OMS actualizó los datos por última vez. Debido al tiempo necesario para procesar y validar los datos entrantes, hay un retraso entre la presentación de informes a la OMS y la actualización del tablero.

Nota 2: Los recuentos y las correcciones realizadas después de estos tiempos se trasladarán al siguiente ciclo de informes para esa región específica. El retraso en la presentación de informes para cualquier país, territorio o área específica puede dar lugar a que se presenten recuentos agrupados de varios días, con una actualización retrospectiva de los recuentos de días anteriores para reflejar con precisión las tendencias. Los errores importantes en los datos detectados o notificados a la OMS podrán corregirse a intervalos más frecuentes.

Fuente: <https://github.com/owid/covid-19-data/tree/master/public/data>


```{r eval=FALSE}
install.packages("bookdown")
# or the development version
# devtools::install_github("rstudio/bookdown")
```


```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

```{r}
if (!require("httr")) install.packages("httr")
library(httr)

# URL para descarga directa
url <- "https://drive.google.com/uc?export=download&id=1CAfxuMVh2PhdocdOyEH2tzDv2uTykwKi"

# Se descarga y lee el archivo:
temp <- tempfile()

options(timeout = 300)
download.file(url, temp)
datos <- read.csv(temp)
unlink(temp)  # Elimina el archivo temporal

# Primeros datos

head(datos, 10)

```




# Análisis Exploratorio de datos:
 
 Iniciamos explorando el conjunto de datos seleccionado, identificando tipos de variables y valores nulos o perdidos:
 
## Exploración y preprocesamiento del dataset:

Inicialmente se exploró el contenido del dataframe identificando 67 variables con 390659 observaciones de pacientes con diagnóstico de covid desde enero del año 2020 hasta febrero del año 2024. Debido a la extensión de esta información, no se presenta el resultado de la función str. 

se continúa con un resumen estadístico que igualmente se decide no presentar dada la extensión de las variables. Llama la atención que se identifica que la variable date está en formato character, se seleccionan solo variables de interés por el momento: date, continent, location, date,new_cases y new_deaths



```{r}

covid <- datos[, c(2, 3, 4, 6, 9)]
str(covid)

```

Se confirma que ya están definidas las variables seleccionadas, ahora se estructura en formato fecha la variable date:

```{r}
covid$date <- as.Date(covid$date, format = "%Y-%m-%d")
summary(covid)
```

Se identifica que ya la fecha se encuentra en el formato indicado, iniciando por el 01 de enero de 2020 y terminando el 15 de abril de 2024 (se actualiza con frecuencia). En la variable nuevos casos se identifica que el 50% de los datos corresponden a 0 pacientes y que hay un valor extremo de 44236227, adicionalmente 10.991 NAs. En la variable nuevas muertes, de igual manera el 50% de las fechas hubo 0 muertes, tiene un valor extremo de 103719 y cuenta con 10.668 NAs.

a continuación se grafican los datos nulos para realizar la depuración de los casos y muertes en valores NA.

```{r message=FALSE, warning=FALSE}
library(mice)
grafico <- md.pattern(covid, rotate.names = TRUE)

```

Se confirma que las dos variables referidas anteriormente contienen datos NA, continente, location y date tienen datos completos.

Según la descripción de las variables en la base de datos original, cuando ocurre un cambio negativo en los datos diarios reportados sobre casos o muertes confirmadas debido a una corrección de datos, en lugar de mostrar un número negativo (lo cual no tendría sentido en este contexto), el valor se establece como "NA" (no disponible) para indicar que la información no está disponible o no es aplicable en esa situación.

En casos excepcionales en los que nuestra fuente de casos y muertes confirmados informa un cambio diario negativo debido a una corrección de datos, configuramos la métrica correspondiente ( new_cases y new_deaths) en NA.

Debido a lo anterior, se decide eliminar los datos como NA dado que no se tuvo información para esas fechas y no tiene sentido aplicar una imputación dado que no corresponden a 0 casos. Sin embargo, solo se eliminan cuando ambas variables contienen NA.

```{r message=FALSE, warning=FALSE}
covid <- subset(covid, !is.na(new_cases) | !is.na(new_deaths))

library(dplyr)

grafico <- md.pattern(covid, rotate.names = TRUE)
```

Quedan eliminados las fechas en las cuales hay NA tanto en nuevos casos como en nuevas muertes.

 
## Estructura y exploración de datos en serie de tiempo:

Se realiza una agrupación de los nuevos casos de covid por mes y se calcula la suma de 'valor'

```{r}
datos_agrupados_casos <- aggregate(new_cases ~ format(date, "%Y-%m"), data = covid, sum)

# Se Renombra la columna resultante
colnames(datos_agrupados_casos) <- c("Mes", "Total")

print(datos_agrupados_casos)
```

Se confirma que se realizó la operación y se le asigna formato de fecha a la variable mes, no se utiliza zoo dado que los valores faltantes no son periódicos ni sistemáticos, entonces, al tener los datos NA ya eliminados, se aplica ts:

```{r}
datos_agrupados_casos$Mes <- as.Date(datos_agrupados_casos$Mes, format = "%Y-%m")

# se establece la fecha de inicio y la frecuencia por meses
indice_casos.ts<-ts(datos_agrupados_casos$Total,start = c(2020,1), frequency = 12)
(indice_casos.ts)
```

**Cálculo de Promedio móvil simple de nuevos casos con ventana de 12 periodos (para una tendencia anual)**:

```{r warning=FALSE}
library(zoo)

promedio_movil_tendencia <- rollmean(indice_casos.ts, k = 12, align = "right", na.pad = TRUE)

par(las=1, mar = c(5, 8, 4, 2) + 0.1)

options(scipen = 999)  # Desactivar la notación científica

plot(promedio_movil_tendencia, type = "l", col = "red",main = "Tendencia de promedio móvil casos nuevos de Covid",xlab = "Fecha", ylab = "", las = 1)

```

En la gráfica se observa que desde el año 2021, la tendencia de nuevos casos de COVID 19 está en aumento con un pico a inicio del año 2023, a partir del cual inicia el descenso marcado.

A continuación se calcula el **Promedio móvil simple con ventana de 3 periodos (para una estacionalidad trimestral)**:

```{r}
promedio_movil_estacionalidad <- rollmean(indice_casos.ts, k = 3, align = "right", na.pad = TRUE)

par(las=1, mar = c(5, 8, 4, 2) + 0.1)

plot(promedio_movil_estacionalidad, type = "l", col = "green",main = "Estacionalidad en casos nuevos de Covid",xlab = "Fecha", ylab = "", las = 1)

```

Con el cálculo del promedio móvil de 3 puntos, cada punto de la gráfica es el promedio de tres puntos consecutivos en la serie de tiempo original. Con align = "right", el promedio móvil se alinea con el último de los tres puntos. Esto ayuda a suavizar la serie, lo que significa que los picos y valles se suavizan para resaltar tendencias subyacentes. Esto es útil para identificar tendencias generales o patrones en la serie de tiempo que podrían no ser evidentes en la serie original, más volátil.

Al observar la gráfica, no se identifican patrones que ocurran en intervalos regulares del tiempo. Se puede calcular autocorrelación para confirmarlo.

```{r}
# Calcular autocorrelación
acf(promedio_movil_estacionalidad, na.action = na.pass)
```

Este grafico muestra los coeficientes de autocorrelación para diferentes retardos (lags) de la serie de tiempo. Interpretación:

_Líneas Hacia Arriba y Hacia Abajo:_ Las barras hacia arriba indican autocorrelación positiva en ese retardo, lo que significa que los valores pasados tienen una relación positiva con los valores actuales.
Las barras hacia abajo indican autocorrelación negativa, lo que significa que los valores pasados tienen una relación negativa con los valores actuales. En la gráfica se observa barras que empiezan hacia arriba y luego hacia abajo, podría indicar un cambio en el patrón de correlación a medida que aumenta el retardo. Esto puede significar que la relación entre los valores pasados y actuales cambia de positiva a negativa.

_Tamaño de las Barras:_ El tamaño de las barras representa la magnitud de la correlación entre los valores de la serie con un retardo específico. Las barras más altas indican una correlación más fuerte.

_Estacionalidad:_ Si hay un patrón periódico en el gráfico, donde las barras suben y bajan en intervalos regulares, es un indicio de estacionalidad. En este caso, no hay un patrón periódico, lo que nos confirma la idea de no estacionalidad.

_Significancia Estadística:_ Las líneas punteadas horizontales representan intervalos de confianza. Las barras que sobrepasan estas líneas indican autocorrelación significativa, la cual se presentó al inicio del periodo solamente.


**Cálculo del promedio móvil de rezago con ventana de 1 periodo** 

```{r}
promedio_movil_rezago <- stats::lag(indice_casos.ts, 1)

par(las=1, mar = c(5, 8, 4, 2) + 0.1)
plot (promedio_movil_rezago,  type = "l", col = "orange",main = "Rezago en casos nuevos de Covid",xlab = "Fecha", ylab = "", las = 1)
```

En la gráfica obtenida se encuentra la serie rezagada desplazada a la derecha en comparación con la serie original. En una gráfica posterior se generará una comparación entre la serie rezagada con la original.

Gráfico de la serie de tiempo original junto con los promedios móviles:

```{r}

options(scipen = 999)
par(las=1, mar = c(5, 8, 4, 2) + 0.1) # Configura el estilo de la etiqueta del eje y en horizontal
plot(indice_casos.ts, main = "Serie de Tiempo Promedios Móviles casos nuevos por Covid 19",
     xlab = "Fecha", ylab = "", col = "blue")
lines(promedio_movil_tendencia, col = "red")
lines(promedio_movil_estacionalidad, col = "green")
lines(promedio_movil_rezago, col = "orange")
legend("topleft", legend = c("Serie de Tiempo", "Promedio Móvil Tendencia", "Promedio Móvil Estacionalidad", "Promedio Móvil de Rezago"),
       col = c("blue", "red", "green", "orange"), lty = 1)
```

De acuerdo a la gráfica anterior con promedios móviles de casos de covid, se concluye que el rezago muestra la observación que ocurre antes la observación de la serie de tiempo y se observa un paralelismo en ambos promedios. En la ocurrencia de casos nuevos se observan dos grandes picos a inicios del año 2022, al finalizar el año  2022 y al iniciar el 2023. 

Desde sus inicios hasta el año 2023 la tendencia de casos nuevos por covid estuvo en aumento, a partir de ahí hasta el 2024 se ha observado un descenso. No se identificó estacionalidad.


```{r}
class(indice_casos.ts)
start(indice_casos.ts)
end(indice_casos.ts)
```

A continuación se realiza el mismo proceso exploratorio con los datos de nuevas muertes de covid por mes.

```{r}
# Agrupar por meses y calcular la suma de 'valor'
datos_agrupados_muertes <- aggregate(new_deaths ~ format(date, "%Y-%m"), data = covid, sum)

# Renombrar la columna resultante
colnames(datos_agrupados_muertes) <- c("Mes", "Total")

print(datos_agrupados_muertes)
```

Se da formato de fecha a los datos:

```{r}
datos_agrupados_muertes$Mes <- as.Date(datos_agrupados_muertes$Mes, format = "%Y-%m")

# se establece la fecha de inicio y la frecuencia por meses
indice_muertes.ts<-ts(datos_agrupados_muertes$Total,start = c(2020,1), frequency = 12)
(indice_muertes.ts)
```

**Promedio móvil simple con ventana de 12 periodos (para una tendencia anual)**
```{r}
promedio_movil_tendenciaM <- rollmean(indice_muertes.ts, k = 12, align = "right", na.pad = TRUE)

par(las=1, mar = c(5, 8, 4, 2) + 0.1)

plot(promedio_movil_tendenciaM, type = "l", col = "red",main = "Tendencia de promedio móvil Muertes por Covid",xlab = "Fecha", ylab = "", las = 1)

```

La tendencia de muertes por covid está incrementándose entre el año 2021 y 2022, a partir de ahí inicia su descenso, es probable que se relacione con un mejor conocimiento sobre el proceso de la enfermedad, el efecto de la vacunación, sin embargo, no es posible afirmarlo solo con los datos con que contamos en este dataset.

**Promedio móvil simple con ventana de 3 periodos (para una estacionalidad trimestral)**
```{r}
promedio_movil_estacionalidadM <- rollmean(indice_muertes.ts, k = 3, align = "right", na.pad = TRUE)

par(las=1, mar = c(5, 8, 4, 2) + 0.1)
plot(promedio_movil_estacionalidadM, type = "l", col = "green",main = "Estacionalidad en Muertes por Covid",xlab = "Fecha", ylab = "", las = 1 )

```

Al observar la gráfica, no se identifica con claridad una estacionalidad, se calcula autocorrelación:

```{r}
acf(promedio_movil_estacionalidadM, na.action = na.pass)
```


_Líneas Hacia Arriba y Hacia Abajo:_ Las barras hacia arriba indican autocorrelación positiva en ese retardo, lo que significa que los valores pasados tienen una relación positiva con los valores actuales.
Las barras hacia abajo indican autocorrelación negativa, lo que significa que los valores pasados tienen una relación negativa con los valores actuales. Similar a la ocurrencia de casos nuevos, En la gráfica de mortalidad se observa barras que empiezan hacia arriba y luego hacia abajo, podría indicar un cambio en el patrón de correlación a medida que aumenta el retardo. Esto puede significar que la relación entre los valores pasados y actuales cambia de positiva a negativa. Los valores negativos que no son significativos probablemente indican ruido o variaciones aleatorias en la serie

_Tamaño de las Barras:_ El tamaño de las barras representa la magnitud de la correlación entre los valores de la serie con un retardo específico. Las barras más altas indican una correlación más fuerte, las cuales se observan hasta el lag 7 sobrepasando las líneas de significancia, esto sugiere que hay una influencia positiva en la serie de tiempo que dura hasta 7 periodos (meses)

_Estacionalidad:_ No se observa un patrón periódico en el gráfico, donde las barras suben y bajan en intervalos regulares, lo que nos confirma la idea de no estacionalidad.

_Significancia Estadística:_ Las líneas punteadas horizontales representan intervalos de confianza. Las barras que sobrepasan estas líneas indican autocorrelación significativa, la cual se presentó al inicio del periodo en los primeros 7 lags, a partir de ahí, la autocorrelación disminuye y ya no es estadísticamente significativa.

**Cálculo del promedio móvil de rezago con ventana de 1 periodo:**

```{r}
promedio_movil_rezagoM <- stats::lag(indice_muertes.ts, 1)

par(las=1, mar = c(5, 8, 4, 2) + 0.1)

plot(promedio_movil_rezagoM, type = "l", col = "orange",main = "Rezago en Muertes por Covid",xlab = "Fecha", ylab = "", las = 1)

```

Como ya vimos el significado de la gráfica del rezago, se describe a continuación, comparando con la tendencia original de muertes por covid.

Gráfico de la serie de tiempo original junto con los promedios móviles:

```{r}
options(scipen = 999)
par(las=1, mar = c(5, 8, 4, 2) + 0.1) # Configura el estilo de la etiqueta del eje y en horizontal
plot(indice_muertes.ts, main = "Serie de Tiempo Promedios Móviles de muertes por Covid",
     xlab = "Fecha", ylab = "", col = "blue")
lines(promedio_movil_tendenciaM, col = "red")
lines(promedio_movil_estacionalidadM, col = "green")
lines(promedio_movil_rezagoM, col = "orange")
legend("topright", legend = c("Serie de Tiempo", "Promedio Móvil Tendencia", "Promedio Móvil Estacionalidad", "Promedio Móvil de Rezago"),
       col = c("blue", "red", "green", "orange"), lty = 1)
```

En la gráfica en conjunto se puede observar en la ocurrencia de muertes por covid se observan tres grandes picos en el año 2021 y uno más pequeño a inicios del año 2022. Aproximadamente a partir del primer trimestre del 2022 se observa una tendencia de disminución de las muertes por Covid. No se identificó una estacionalidad en la ocurrencia de muertes.

# Descomposición de la serie de tiempo.

**Descomposición:**

Se descompone  la serie de tiempo en sus componentes de tendencia, estacionalidad y error. Esto es útil para entender mejor la estructura de la serie y analizar patrones subyacentes.

En este caso, se puede utilizar la función  decompose dado que los datos sean regulares (intervalos uniformes mensuales) y se estableció la frecuencia de 12 para datos mensuales.

Se utilizarán los datos de casos nuevos de Covid 19.

```{r}
covidcomp <- decompose(indice_casos.ts)
plot(covidcomp)
```

En la primera gráfica se observa la serie original como se había descrito anteriormente.

En la segunda gráfica (Trend) observamos la tendencia de los casos nuevos de covid en el tiempo, una línea suavizada que representa el movimiento general a largo plazo.

La tercera gráfica (seasonal) vemos la estacionalidad, muestra el patrón repetitivo que ocurre en intervalos regulares. A diferencia de la primera gráfica generada, en esta descomposición sí parece que existiera un patrón con picos a inicio de cada año y un pequeño incremento en la mitad del año.

Y en la última gráfica (random) Ruido, se muestra el residuo que queda después de eliminar tendencia y estacionalidad. Representa variaciones aleatorias o ruido en los datos. Idealmente, debería parecer una línea plana alrededor de cero si la descomposición es adecuada, sin embargo, se observa con claridad que no hay una línea plana y que en el año 2021, hay una disminución, mientras que en el año 2022 y 2023 hay picos.


**Estacionariedad:**

La estacionariedad es una propiedad de los datos en la que sus características estadísticas, como la media, la varianza y la autocorrelación, se mantienen constantes a lo largo del tiempo. Esta es una propiedad importante para muchos métodos de análisis y modelado de series temporales.

Una serie estacionaria tiene media constante, varianza constante y autocorrelación constante. Con datos estacionarios se facilita el modelado, pues algunos modelos como el ARIMA asumen que los datos son estacionarios, se mejora el pronóstico y la identificación de patrones.

Para verificar la estacionariedad en los datos de casos nuevos por COVID 19, se utilizará la prueba de Dickey-Fuller aumentado (ADF). El paquete aTSA proporciona una implementación de esta prueba.

```{r message=FALSE, warning=FALSE}
library(tseries)
covid_adf <- adf.test(indice_casos.ts)
print (covid_adf)
```

El valor p es 0.4587, indica que no hay suficiente evidencia para rechazar la hipótesis nula de que la serie no es estacionaria, en estos casos, se requeriría transformar o diferenciar los datos para que sean estacionarios.

Para ello se podría diferenciar la serie de datos, tomar diferencias sucesivas de la serie para convertirla en estacionaria.

```{r warning=FALSE}
covid_ts_diff <- diff(indice_casos.ts)

#Y se repite la prueba para verificar si funcionó la diferenciación y la serie ahora es estacionaria

covid_adf <- adf.test(covid_ts_diff)
print (covid_adf)

```
Ahora se obtiene un valor p menor de 0.01, indica que ya es posible rechazar la hipótesis nula y concluir que la serie es estacionaria después de la primera diferenciación.

Con esta variable diferenciada, es posible proceder con un análisis o modelado asumiendo que los datos son estacionarios. Se pueden emplear modelos de serie de tiempo como ARIMA, que requieren estacionariedad.

Adicionalmente, previo al uso de ARIMA, se aplicarán las funciones acf (Autocorrelation Function) y pacf (Partial Autocorrelation Function) para examinar las relaciones entre los valores de la serie en diferentes retardos (lags). Estas dos funciones son herramientas clave para entender patrones y seleccionar modelos de series temporales, como ARIMA.

```{r}
covidcompDiff <- decompose(covid_ts_diff)
plot(covidcompDiff)
```

En la gráfica anterior identificamos que después de diferenciar los datos, se observa que cambia la tendencia, se mantiene un patrón en la estacionalidad y el ruido sigue presentando picos.

Se procede a realizar una segunda diferenciación, dado que a veces, una única diferenciación no es suficiente:

```{r}
covid_ts_diff2 <- diff(covid_ts_diff)

covidcompDiff2 <- decompose(covid_ts_diff2)
plot(covidcompDiff2)

```

Con la segunda diferenciación, el ruido se mantiene. A continuación, se realiza una transformación Box Cox para estabilizar la varianza.

```{r}
library(forecast)
# Encontrar el valor óptimo de lambda para la transformación de Box-Cox
lambda_optimo <- BoxCox.lambda(indice_casos.ts)

covid_boxcox <- BoxCox(indice_casos.ts, lambda = lambda_optimo)

```

Con los datos transformados, se realiza una nueva descomposición:

```{r}
covidBox <- decompose(covid_boxcox)
plot(covidBox)
```

Se raliza cálculo de Dickey Fuller para evaluar si hay estacionariedad con los datos transformados mediante Boxcox

```{r}
covid_adfBox <- adf.test(covid_boxcox)
print (covid_adfBox)
```

El resultado de la prueba Dickey-Fuller  con los datos transformados conBoxCox indica que el valor p = 0.6268 es mayor que el umbral de significancia, lo que significa que rechazamos la hipótesis nula de que la serie no es estacionaria. 

En Resumen, con la transformación Box Cox, se redujo el Random, pero no se mejora la estacionariedad.


**Nota:**

Al encontrar que no había estacionariedad, se realizó una diferenciación de los datos, logrando después de ello la estacionariedad comprobada con la prueba estadística Dickey-Fuller, no obstante, al descomponer de nuevo, se sigue presentando alta variación en el random. 

Para mejorar esta variación se realizó una segunda diferenciación, la cual se mantuvo con alta variación en Random.

Se realizó una transformación Box Cox, posterior a la cual los observados y las tendencias se suavizan, el random tuvo menos variaciones pero sin estacionariedad.

De acuerdo a lo anterior, se calculan las funciones de autocorrelación con los datos diferenciados una vez.


**ACF: Función de Autocorrelación**

Mide la correlación entre la serie original y versiones desplazadas (lags) de sí misma. Los valores en el gráfico muestran la correlación total entre la serie y los valores en retardos específicos, los ACF pueden ayudar a determinar el orden de los componentes MA en un modelo ARIMA.

```{r}
acf(covid_ts_diff)

```

Los picos que sobresalen de las líneas de significancia sugieren retardos con autocorrelación significativa. En este caso, solo se observan dos picos, uno al inicio y otro en el lag 0.9.


**PACF: Función de Autocorrelación Parcial**

Mide la correlación entre una serie y sus retardos eliminando la influencia de los retardos intermedios. Los valores significativos en el gráfico PACF sugieren el orden de los componentes AR en un modelo ARIMA.

```{r}
pacf(covid_ts_diff)

```

Todos los picos en el gráfico de PACF están dentro de las líneas de significancia, generalmente indica que no hay autocorrelaciones parciales significativas entre la serie de tiempo y sus retardos. Esto sugiere que la serie no tiene un fuerte componente autorregresivo, al menos en los retardos observados. Si ningún pico sobresale de las líneas de significancia, el componente AR del modelo ARIMA puede ser insignificante. Esto significa que la serie probablemente no tiene una fuerte dependencia autorregresiva, es decir que los valores pasados de la serie no están influyendo significativamente en los valores actuales, que la serie se comporta de forma más aleatoria y no sigue patrones claros que se puedan identificar fácilmente a partir de los valores pasados.

Con lo anterior, Los modelos autorregresivos (AR) no serían útiles para modelar la serie. En este caso, se podrían examinar otras características de la serie. Como el ACF muestra picos significativos, es posible que un modelo MA sea más apropiado, también se podría considerar modelos más complejos como SARIMA.


# Modelización

## Método de Holt-Winter:


El suavizado exponencial de Holt-Winter es una de las técnicas de análisis de series de tiempo más antiguas que tiene en cuenta la tendencia y la estacionalidad al hacer el pronóstico. Este método tiene 3 aspectos principales para realizar las predicciones que son tres tipos de suavizado exponencial. Tiene un valor medio con la tendencia y la estacionalidad.

**Descripción ampliada de los datos:**

Iniciamos graficando nuevamente el índice de los casos nuevos de Covid a través del tiempo


```{r}

plot((indice_casos.ts),ylab="(indice_casos)",xlab='Año', main ='Casos nuevos de Covid')

time_indices <- time(indice_casos.ts)
modelo <- lm(indice_casos.ts ~ time_indices)
abline(modelo, col = "red", lwd = 2)

```

En la gráfica anterior se observa la tendencia y el comportamiento de los casos nuevos de covid.

```{r}
cycle(indice_casos.ts)
```

Con la función cycle se identifica el ciclo al que pertenece cada dato en la serie temporal, en nuestro caso, tenemos datos agrupados por mes con una frecuencia de 12, esta función asigna un número del 1 al 12 a cada mes. Posteriormente calculamos una medida resumen para cada periodo, en este caso un promedio mensual.

```{r}
plot(aggregate(indice_casos.ts, FUN = mean))

```

Se observa claramente los meses pico con tendencia más alta, en la gráfica es a inicio del 2022.


```{r}
boxplot(indice_casos.ts~cycle(indice_casos.ts))
```

En la gráfica anterior, cada caja indica la variabilidad de los casos nuevos dentro de cada mes, las cajas más anchas indican mayor variabilidad en el mes como en los meses de enero y diciembre.

Se observa la mediana de casos nuevos de covid de forma mensual, con una mediana mayor en los meses de mayor variabilidad y agosto. La menor se encuentra en febrero y marzo, siendo ambos meses los que tienen datos outlier.


A través de la función logaritmo que se aplica a continuación, se busca visualizar mejor los datos de casos nuevos de covid:

```{r}

plot(log(indice_casos.ts),ylab="log(Casos nuevos)",xlab='Año', main ='Logaritmo de casos nuevos de Covid')

```

Como se puede ver en la gráfica anterior, se evidencia una transformación de los datos, destacando una reducción en la variabilidad y una mayor estabilidad a lo largo del tiempo. Entre el año 2020 y 2021 la tendencia es creciente en número de casos, parece más estable con algunas variaciones entre el año 2021 y 2023, a partir de ahí, se observa decreciente.


**Aplicación del modelo Holt-Winter:**

Teniendo en cuenta la transformación anterior, procedemos a aplicar el modelo de Holt - Winter utilizando la manera aditiva:

```{r}
modelo_HW = HoltWinters(log(indice_casos.ts), seasonal="additive")
plot(modelo_HW, main="Ajuste con Holt-Winters", xlab="Año",ylab="log(Casos nuevos)")
```

Con la aplicación de este método, se crea una línea de color rojo con una nueva serie de datos, en la cual se puede observar una proximidad entre los puntos con los datos originales color negro. Al aplicar el método de Holt-Winter para ajustar los datos, se nota que este método es adecuado, ya que sigue de buena forma el comportamiento de los datos, con una leve variación en el año 2022, sin embargo, se observa un buen ajuste.


A continuación, se descompone la serie de acuerdo a las características: 

```{r}
plot(fitted(modelo_HW), main="Descomposición con HW",xlab="Año",ylab="log(Casos nuevos)", col = "blue")

```

Se puede evidenciar en la gráfica, que con las transformaciones realizadas se reduce el Random, lo que puede ayudar a generar una buena predicción. 

Xhat grafica los valores ajustados, representa la estimación ajustada de la serie temporal basándose en el modelo Holt-Winters. Muestra cómo el modelo captura la tendencia y la estacionalidad.

El level o nivel indica el nivel subyacente de la serie de nuevos casos de covid en cada punto del tiempo. Es una estimación suave del promedio de la serie en el tiempo. Refleja una tendencia al final descendente.

El trend  o tendencia refleja el componente de tendencia de la serie temporal. Es la velocidad a la que el nivel está cambiando con el tiempo. La tendencia observada es decreciente.

La gráfica de Season o estacionalidad muestra si hay patrones cíclicos, lo cual no es evidente en este caso. Cada valor estacional se calcula respecto al promedio general (nivel).


**Predicción:**


Ahora, se realizará la predicción para el año siguiente (12 meses) de los casos nuevos de Covid

```{r}
pred=predict(modelo_HW, 12, prediction.interval = TRUE)
pred
```
```{r}
plot(modelo_HW,pred)
```

De esta forma se puede observar la tendencia del comportamiento para los próximos 12 meses, con sus respectivos intervalos de confianza, la cual se presenta en descenso.

## Método de Suavizamiento Exponencial:

El suavizamiento exponencial es un tipo de promedio ponderado que estima el valor futuro en función del pronóstico anterior más un porcentaje de error pronosticado.


```{r warning=FALSE}
library(forecast)
fit_ses<-ses(log(indice_casos.ts),h=1, initial="simple",alpha=0.1)
fit_ses
```

El pronóstico es de 15.84 con los intervalos de predicción Lo(bajo) y Hi (Alto)

```{r}
summary(fit_ses)
```
```{r}
plot(fit_ses)
```

El valor pronosticado para abril de 2024 sería de 15.8 casos nuevos de covid con un intervalo 95% entre 10 y 21 casos. en general, con el suavizado, se mantiene la tendencia a la disminución en el número de casos nuevos.


## Modelos estacionarios en series de tiempo: Metodología Box-Jenkins

Se aplica a los modelos autorregresivos de media móvil ARMA o a los modelos autorregresivos integrados de media móvil ARIMA para encontrar el mejor ajuste de una serie temporal con el fin de que los pronósticos sean más acertados.

Dentro de los pasos a seguir, tenemos:

* Visualizar la serie.
* Transformarla en estacionaria.
* Graficar ACF - PACF, escoger los parámetros.
* Construir el modelo.
* Hacer predicción.

**Visualizar la Serie y transformarla en estacionaria:**

Como se expuso en el punto 3. de este documento, el valor p de la prueba de Dickey-Fuller aumentado (ADF)es 0.4587, indica que no hay suficiente evidencia para rechazar la hipótesis nula de que la serie no es estacionaria, en estos casos, se requeriría transformar o diferenciar los datos para que sean estacionarios. 

En ese caso, se aplicó una primera diferenciación en la variable covid_ts_diff dónde se obtuvo un valor p menor de 0.01, indica que ya es posible rechazar la hipótesis nula y concluir que la serie es estacionaria después de la primera diferenciación.

**Graficar ACF - PACF, escoger los parámetros:**

Se realiza gráfico de las Funciones de autocovarianza (ACF) y autocorrelación (PACF):

```{r}

par(mfrow = c(1, 2))
ACF_dif1<-acf(covid_ts_diff)
PACF_dif1<-pacf(covid_ts_diff)
```

La descripción de estas gráficas ya fue realizada.


**Construir el modelo y hacer predicción:**

Teniendo en cuenta esto, se procede a aplicar el modelo sugerido ARIMA:

```{r message=FALSE, warning=FALSE}
library(forecast)

modelo_dif1<-auto.arima(covid_ts_diff)
modelo_dif1
pronostico_dif1<- forecast(modelo_dif1,12,level=95)
pronostico_dif1
plot(pronostico_dif1,main="Pronóstico con Arima para Casos nuevos de Covid con diferenciación",xlab="Año",ylab="covid_ts_diff")
grid()

```

En resumen, el modelo ARIMA(0,0,2) con media cero refleja coeficientes significativos para los términos de media móvil, pero la alta varianza de los residuos y los valores altos de AIC, AICc y BIC indican que el modelo puede no ser óptimo y puede necesitar una revisión o ajuste adicional.

Además como se evidencia en la gráfica, si el pronóstico es el mismo para todos los meses, eso indica que hay un problema con el modelo ajustado.

Por lo anterior, se tomará la variable covid_ts_diff2 en dónde se procedió a realizar una segunda diferenciación para ver si se ajusta el modelo, antes de eso, nuevamente se procede a graficar las Funciones de autocovarianza (ACF) y autocorrelación (PACF) para estos datos:

```{r}
par(mfrow = c(1, 2))

ACF_dif2<-acf(covid_ts_diff2)
PACF_dif2<-pacf(covid_ts_diff2)
```


```{r}
modelo_dif2<-auto.arima(covid_ts_diff2)
modelo_dif2
pronostico_dif2<- forecast(modelo_dif2,12,level=95)
pronostico_dif2
plot(pronostico_dif2,main="Pronóstico con Arima para Casos nuevos de Covid con segunda diferenciación",xlab="Año",ylab="covid_ts_diff2")
grid()
```
 
Este modelo ARIMA indica que se utilizan cinco términos autorregresivos (AR) y un término de media móvil (MA), sin aplicar diferenciación (I), y el modelo no incluye un término constante distinto de cero.  En resumen, el modelo ARIMA(5,0,1) parece capturar bien la estructura de la serie temporal "covid_ts_diff2", con coeficientes significativos para los términos AR y MA. Sin embargo, siempre es importante validar el modelo y considerar si hay margen para mejorar el ajuste.
 
Ademas el pronóstico demostrado en la gráfica presenta valores muy pequeños para todos los meses.

Por lo anterior, se procede a aplicar logaritmo a la serie inicial para ajustar la estacionariedad y para poder mejorar el pronóstico, al igual que en los dos casos anteriores, se realiza primero el gráfico de las Funciones de autocovarianza (ACF) y autocorrelación (PACF):

```{r}

par(mfrow = c(1, 2))
ACF_log<-acf(log(indice_casos.ts))
PACF_log<-pacf(log(indice_casos.ts))
```

Se continua con el cálculo:

```{r}
modelo_log<-auto.arima(log(indice_casos.ts))
modelo_log
pronostico_log<- forecast(modelo_log,12,level=95)
pronostico_log
plot(pronostico_log,main="Pronóstico con Arima para Casos nuevos de Covid con transformación Log",xlab="Año",ylab="Log_indice_Casos")
grid()
```

De acuerdo con los resultados, se puede evidenciar que este modelo ARIMA indica que se utiliza un término de media móvil (MA) de orden 1 (q=1), sin términos autorregresivos (AR) (p=0), y se ha aplicado una diferenciación de segundo orden (d=2) a la serie temporal original.

El modelo ARIMA (0,2,1) ajustado a la serie con transformación log, proporciona una aproximación adecuada, con un solo término de media móvil y una diferenciación de segundo orden. Al aplicar esta transformación se obtiene un pronóstico más acertado, el cual también refleja una tendencia de disminución en los próximos 12 meses, lo que concuerda con la realidad observada en los nuevos casos de Covid. Por lo tanto, este pronóstico puede ser considerado como acertado para esta serie temporal.

Teniendo en cuenta lo anterior, se procede a calcular y graficar los residuales: 

```{r}
residuales<-modelo_log$residuals
residuales
qqnorm(residuales)
qqline(residuales)
```

Los residuales representan la diferencia entre los valores observados y los valores predichos por el modelo. En este contexto, los residuales son las discrepancias entre los valores reales y los valores pronosticados para cada mes de los años 2020 a 2023.

Ahora aplicaremos el Test Shapiro con el fin de validar si los residuales presentan una distribución normal:

```{r}
shapiro.test(residuales)
```

Se puede evidenciar que el valor W =0.98 es cercano a 1, lo que significa que los residuales no se desvían significativamente de una distribución normal, ya que cuanto más cercano esté a 1, más consistentes son los datos con una distribución normal.

Por otro lado con el valor p se puede observar si los datos provienen de una población con una distribución normal. Un valor p alto (generalmente mayor que 0.05) indica que no hay suficiente evidencia para rechazar la hipótesis nula de que los datos provienen de una distribución normal. En este caso, el valor p es 0.6831, lo que sugiere que los datos tienen una distribución normal, .

Teniendo en cuenta lo anterior, se puede determinar que el modelo ARIMA ajustado es adecuado para los datos.

Finalmente aplicamos el Box-Ljung test para verificar la presencia de autocorrelación en los residuos del modelo:

```{r}
Box.test(residuales,type = "Ljung-Box")
```

El resultado del test de Box-Ljung X-squared = 0.77733 y p = 0.378 indican que no hay suficiente evidencia para afirmar que exista autocorrelación significativa en los residuales del modelo de series temporales. Por lo tanto, no se puede afirmar que haya autocorrelación en los residuales generando un impacto positivo en el modelo:

* Las predicciones del modelo no están sistemáticamente sesgadas por patrones no modelados,

* Hay independencia de los errores reforzando la confianza en los resultados,

* Los intervalos de confianza y las pruebas de hipótesis derivadas del modelo son más confiables

* Los estimadores de los coeficientes del modelo son eficientes y tienen varianza mínima dando precisión a las estimaciones, y

* Los errores en una observación no son predictivos de los errores en las observaciones futuras.



